# Context Tool LLM API ä½¿ç”¨è¯´æ˜

> **è´Ÿè´£äºº**: æˆå‘˜D  
> **å®Œæˆæ—¥æœŸ**: 2026-01-17  
> **çŠ¶æ€**: âœ… å·²æ¥å…¥ LLM API

---

## ğŸ“‹ å¿«é€Ÿå¼€å§‹

### å‰ç½®æ¡ä»¶

1. **å®‰è£…ä¾èµ–**
   ```bash
   pip install openai
   ```

2. **APIé…ç½®**ï¼ˆå·²å†…ç½®ï¼Œæ— éœ€é¢å¤–é…ç½®ï¼‰
   - API Key: `sk-0d73949767524be2989b35415d2ccbe0`
   - Base URL: `https://api.tokenpony.cn/v1`
   - Model: `qwen3-coder-480b`

### æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼

```python
from openai import OpenAI
from src.tools.context_tool import analyze_context

# 1. åˆ›å»ºLLMå®¢æˆ·ç«¯
llm_client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
llm_client._model = "qwen3-coder-480b"

# 2. è°ƒç”¨å‡½æ•°ï¼ˆä¼ å…¥llm_clientï¼‰
result = analyze_context(
    original_sentence="å´‡æœå…¶é›¨",  # åŸå§‹å¥å­
    char_a="å´‡",                    # è¢«é‡Šå­—
    char_b="çµ‚",                    # é‡Šå­—
    meaning_a="é«˜ï¼›é«˜å¤§",           # Açš„æœ¬ä¹‰
    meaning_b="ç»ˆç»“ã€æ•´ä¸ª",         # Bçš„æœ¬ä¹‰
    llm_client=llm_client           # ä¼ å…¥LLMå®¢æˆ·ç«¯
)

# 3. æŸ¥çœ‹ç»“æœ
print(f"ç»“è®º: {result['ç»“è®º']}")        # "æ”¯æŒå‡å€Ÿ"
print(f"Aæœ¬ä¹‰é€šé¡º: {result['Aæœ¬ä¹‰é€šé¡º']}")  # False
print(f"Bæœ¬ä¹‰é€šé¡º: {result['Bæœ¬ä¹‰é€šé¡º']}")  # True
print(f"ç†ç”±: {result['ç†ç”±']}")
```

---

## ğŸ”§ ä¸‰ç§ä½¿ç”¨æ–¹å¼

### æ–¹å¼1ï¼šå‡½æ•°å¼æ¥å£ï¼ˆæœ€ç®€å•ï¼Œæ¨èï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šå¿«é€Ÿè°ƒç”¨ï¼Œä¸éœ€è¦å¤ç”¨å·¥å…·å®ä¾‹

```python
from openai import OpenAI
from src.tools.context_tool import analyze_context

# åˆ›å»ºå®¢æˆ·ç«¯
llm_client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
llm_client._model = "qwen3-coder-480b"

# ç›´æ¥è°ƒç”¨
result = analyze_context(
    original_sentence="å´‡æœå…¶é›¨",
    char_a="å´‡",
    char_b="çµ‚",
    meaning_a="é«˜ï¼›é«˜å¤§",
    meaning_b="ç»ˆç»“ã€æ•´ä¸ª",
    llm_client=llm_client
)

print(result["ç»“è®º"])  # "æ”¯æŒå‡å€Ÿ"
```

**ä¼˜ç‚¹**ï¼š
- ä»£ç ç®€æ´
- é€‚åˆä¸€æ¬¡æ€§è°ƒç”¨
- è‡ªåŠ¨ç®¡ç†å·¥å…·å®ä¾‹

---

### æ–¹å¼2ï¼šç±»å¼æ¥å£ï¼ˆé€‚åˆæ‰¹é‡è°ƒç”¨ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šéœ€è¦å¤šæ¬¡è°ƒç”¨ï¼Œå¤ç”¨å·¥å…·å®ä¾‹

```python
from openai import OpenAI
from src.tools.context_tool import ContextTool

# 1. åˆ›å»ºLLMå®¢æˆ·ç«¯
llm_client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
llm_client._model = "qwen3-coder-480b"

# 2. åˆ›å»ºå·¥å…·å®ä¾‹ï¼ˆåªéœ€åˆ›å»ºä¸€æ¬¡ï¼‰
tool = ContextTool(llm_client=llm_client)

# 3. å¤šæ¬¡è°ƒç”¨ï¼ˆå¤ç”¨åŒä¸€ä¸ªå®ä¾‹ï¼‰
result1 = tool.analyze(
    original_sentence="å´‡æœå…¶é›¨",
    char_a="å´‡",
    char_b="çµ‚",
    meaning_a="é«˜ï¼›é«˜å¤§",
    meaning_b="ç»ˆç»“ã€æ•´ä¸ª"
)

result2 = tool.analyze(
    original_sentence="ç»å¬æ˜Šå¤©ï¼Œäº‘å¦‚ä½•å´‡",
    char_a="å´‡",
    char_b="çµ‚",
    meaning_a="é«˜ï¼›é«˜å¤§",
    meaning_b="ç»ˆç»“ã€æ•´ä¸ª"
)

print(result1.conclusion)  # "æ”¯æŒå‡å€Ÿ"
print(result2.conclusion)  # "æ”¯æŒè¯­ä¹‰"
```

**ä¼˜ç‚¹**ï¼š
- å¯ä»¥å¤ç”¨å·¥å…·å®ä¾‹
- é€‚åˆæ‰¹é‡å¤„ç†
- æ›´çµæ´»çš„æ§åˆ¶

---

### æ–¹å¼3ï¼šè‡ªåŠ¨åˆå§‹åŒ–ï¼ˆä½¿ç”¨å†…ç½®é…ç½®ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šä¸æƒ³æ‰‹åŠ¨åˆ›å»ºå®¢æˆ·ç«¯ï¼Œä½¿ç”¨é»˜è®¤é…ç½®

```python
from src.tools.context_tool import ContextTool

# ä½¿ç”¨ auto_init=Trueï¼Œè‡ªåŠ¨åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨å†…ç½®APIé…ç½®ï¼‰
tool = ContextTool(auto_init=True)

# ä½¿ç”¨å·¥å…·
result = tool.analyze(
    original_sentence="å´‡æœå…¶é›¨",
    char_a="å´‡",
    char_b="çµ‚",
    meaning_a="é«˜ï¼›é«˜å¤§",
    meaning_b="ç»ˆç»“ã€æ•´ä¸ª"
)

print(result.conclusion)  # "æ”¯æŒå‡å€Ÿ"
```

**æ³¨æ„**ï¼šæ­¤æ–¹å¼ä½¿ç”¨ä»£ç ä¸­ç¡¬ç¼–ç çš„APIé…ç½®ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•ã€‚

---

## ğŸ“– å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåœ¨Agentä¸­ä½¿ç”¨

```python
from openai import OpenAI
from src.agent.xungu_agent import XunguAgent

# åˆ›å»ºLLMå®¢æˆ·ç«¯
llm_client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
llm_client._model = "qwen3-coder-480b"

# åˆ›å»ºAgentï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨LLMè¿›è¡Œè¯­å¢ƒåˆ†æï¼‰
agent = XunguAgent(llm_client=llm_client)

# åˆ†æè®­è¯‚å¥ï¼ˆç¬¬äº”æ­¥ä¼šè‡ªåŠ¨è°ƒç”¨context_toolï¼‰
result = agent.analyze(
    xungu_sentence="å´‡ï¼Œçµ‚ä¹Ÿ",
    context="å´‡æœå…¶é›¨"
)

print(f"åˆ†ç±»: {result.classification}")
print(f"ç¬¬äº”æ­¥ç»“è®º: {result.step5_context['ç»“è®º']}")
```

### ç¤ºä¾‹2ï¼šå•ç‹¬ä½¿ç”¨è¯­å¢ƒåˆ†æ

```python
from openai import OpenAI
from src.tools.context_tool import analyze_context
from src.tools.semantic_tool import query_word_meaning

# åˆ›å»ºLLMå®¢æˆ·ç«¯
llm_client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
llm_client._model = "qwen3-coder-480b"

# 1. å…ˆæŸ¥è¯¢ä¸¤ä¸ªå­—çš„æœ¬ä¹‰
meaning_a = query_word_meaning("å´‡")
meaning_b = query_word_meaning("çµ‚")

# 2. è¿›è¡Œè¯­å¢ƒåˆ†æ
result = analyze_context(
    original_sentence="å´‡æœå…¶é›¨",
    char_a="å´‡",
    char_b="çµ‚",
    meaning_a=meaning_a["æœ¬ä¹‰"],
    meaning_b=meaning_b["æœ¬ä¹‰"],
    llm_client=llm_client
)

# 3. è¾“å‡ºç»“æœ
print("=" * 60)
print("è¯­å¢ƒåˆ†æç»“æœ")
print("=" * 60)
print(f"åŸå¥: å´‡æœå…¶é›¨")
print(f"ç”¨'å´‡'æœ¬ä¹‰ç†è§£: {result['Aè§£é‡Š']}")
print(f"ç”¨'çµ‚'æœ¬ä¹‰ç†è§£: {result['Bè§£é‡Š']}")
print(f"ç»“è®º: {result['ç»“è®º']}")
print(f"ç†ç”±: {result['ç†ç”±']}")
```

### ç¤ºä¾‹3ï¼šæ‰¹é‡å¤„ç†æµ‹è¯•é›†

```python
from openai import OpenAI
from src.tools.context_tool import ContextTool
from src.evaluation.test_dataset import load_test_dataset
from src.tools.semantic_tool import query_word_meaning

# åˆ›å»ºLLMå®¢æˆ·ç«¯
llm_client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
llm_client._model = "qwen3-coder-480b"

# åˆ›å»ºå·¥å…·å®ä¾‹ï¼ˆå¤ç”¨ï¼‰
tool = ContextTool(llm_client=llm_client)

# åŠ è½½æµ‹è¯•é›†
dataset = load_test_dataset("data/test/test_dataset.json")

# æ‰¹é‡åˆ†æ
results = []
for case in dataset:
    if case.context:  # åªåˆ†ææœ‰ä¸Šä¸‹æ–‡çš„æ¡ˆä¾‹
        # æŸ¥è¯¢æœ¬ä¹‰
        meaning_a = query_word_meaning(case.char_a)
        meaning_b = query_word_meaning(case.char_b)
        
        # è¯­å¢ƒåˆ†æ
        result = tool.analyze(
            original_sentence=case.context,
            char_a=case.char_a,
            char_b=case.char_b,
            meaning_a=meaning_a["æœ¬ä¹‰"],
            meaning_b=meaning_b["æœ¬ä¹‰"]
        )
        
        results.append({
            "id": case.id,
            "context": case.context,
            "conclusion": result.conclusion,
            "expected": case.expected_label
        })

# ç»Ÿè®¡
print(f"å…±åˆ†æ {len(results)} ä¸ªæ¡ˆä¾‹")
for r in results[:5]:
    print(f"ID {r['id']}: {r['conclusion']} (æœŸæœ›: {r['expected']})")
```

---

## ğŸ“Š è¿”å›æ•°æ®æ ¼å¼

### å‡½æ•°å¼æ¥å£è¿”å›

```python
{
    "Aæœ¬ä¹‰é€šé¡º": False,              # è¢«é‡Šå­—æœ¬ä¹‰ä»£å…¥æ˜¯å¦é€šé¡º
    "Bæœ¬ä¹‰é€šé¡º": True,               # é‡Šå­—æœ¬ä¹‰ä»£å…¥æ˜¯å¦é€šé¡º
    "Aè§£é‡Š": "ç”¨'é«˜ï¼›é«˜å¤§'ç†è§£ï¼š'é«˜å¤§æ—©æ™¨ä¸‹é›¨'ï¼Œè¯­ä¹‰ä¸é€š",
    "Bè§£é‡Š": "ç”¨'ç»ˆç»“ã€æ•´ä¸ª'ç†è§£ï¼š'æ•´ä¸ªæ—©æ™¨ä¸‹é›¨'ï¼Œè¯­ä¹‰é€šé¡º",
    "ç»“è®º": "æ”¯æŒå‡å€Ÿ",              # "æ”¯æŒå‡å€Ÿ" / "æ”¯æŒè¯­ä¹‰" / "ä¸ç¡®å®š"
    "ç†ç”±": "è¢«é‡Šå­—'å´‡'çš„æœ¬ä¹‰'é«˜ï¼›é«˜å¤§'ä»£å…¥åŸå¥ä¸é€šé¡ºï¼Œè€Œé‡Šå­—'çµ‚'çš„æœ¬ä¹‰'ç»ˆç»“ã€æ•´ä¸ª'ä»£å…¥åé€šé¡ºï¼Œç¬¦åˆå‡å€Ÿç‰¹å¾"
}
```

### ç±»å¼æ¥å£è¿”å›

```python
ContextAnalysis(
    char_a_fits=False,              # bool
    char_b_fits=True,              # bool
    char_a_interpretation="...",  # str
    char_b_interpretation="...",  # str
    conclusion="æ”¯æŒå‡å€Ÿ",         # str
    reasoning="..."                # str
)
```

---

## ğŸ” å·¥ä½œåŸç†

### å·¥ä½œæµç¨‹

```
ç”¨æˆ·è°ƒç”¨ analyze()
    â†“
æ£€æŸ¥æ˜¯å¦æœ‰ llm_client?
    â”œâ”€ æœ‰ â†’ _analyze_with_llm()  â† ä½¿ç”¨çœŸå®LLM API
    â”‚         â†“
    â”‚     1. æ„å»ºæç¤ºè¯ (_build_prompt)
    â”‚     2. è°ƒç”¨LLM API (chat.completions.create)
    â”‚     3. è§£æJSONå“åº” (_parse_response)
    â”‚     4. è¿”å› ContextAnalysis
    â”‚
    â””â”€ æ—  â†’ _analyze_mock()  â† ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
              â†“
          è¿”å›é¢„è®¾çš„æ¨¡æ‹Ÿç»“æœ
```

### LLMæç¤ºè¯ç¤ºä¾‹

å·¥å…·ä¼šæ„å»ºå¦‚ä¸‹æç¤ºè¯å‘é€ç»™LLMï¼š

```
ä½ æ˜¯ä¸€ä½å¤æ±‰è¯­ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å¥å­ä¸­ï¼Œç”¨ä¸åŒå­—ä¹‰ä»£å…¥åçš„è¯­ä¹‰é€šé¡ºåº¦ã€‚

åŸå¥ï¼šå´‡æœå…¶é›¨

åˆ†æä»»åŠ¡ï¼š
1. å°†"å´‡"æŒ‰å…¶æœ¬ä¹‰"é«˜ï¼›é«˜å¤§"ç†è§£ï¼Œåˆ¤æ–­å¥å­æ˜¯å¦é€šé¡º
2. å°†"å´‡"ç†è§£ä¸º"çµ‚"ï¼ˆæœ¬ä¹‰ï¼šç»ˆç»“ã€æ•´ä¸ªï¼‰ï¼Œåˆ¤æ–­å¥å­æ˜¯å¦é€šé¡º

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
{
    "char_a_fits": true/false,
    "char_b_fits": true/false,
    "char_a_interpretation": "ç”¨Aæœ¬ä¹‰çš„å¥å­è§£é‡Š",
    "char_b_interpretation": "ç”¨Bæœ¬ä¹‰çš„å¥å­è§£é‡Š",
    "conclusion": "æ”¯æŒå‡å€Ÿ/æ”¯æŒè¯­ä¹‰/ä¸ç¡®å®š",
    "reasoning": "åˆ¤æ–­ç†ç”±"
}
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### APIé…ç½®ä½ç½®

ä»£ç ä¸­å·²å†…ç½®APIé…ç½®ï¼ˆ`src/tools/context_tool.py` ç¬¬62-64è¡Œï¼‰ï¼š

```python
api_key = "sk-0d73949767524be2989b35415d2ccbe0"
base_url = "https://api.tokenpony.cn/v1"
model = "qwen3-coder-480b"
```

### ç¯å¢ƒå˜é‡é…ç½®ï¼ˆå¯é€‰ï¼‰

ä¹Ÿå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼š

```bash
export OPENAI_API_KEY="sk-0d73949767524be2989b35415d2ccbe0"
export OPENAI_BASE_URL="https://api.tokenpony.cn/v1"
export LLM_MODEL="qwen3-coder-480b"
```

ç„¶ååœ¨ä»£ç ä¸­ä½¿ç”¨ï¼š

```python
from src.tools.context_tool import ContextTool

# ä½¿ç”¨ auto_init=Trueï¼Œä¼šè‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡
tool = ContextTool(auto_init=True)
```

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### è¿è¡Œæµ‹è¯•

```bash
# æµ‹è¯•LLM APIæ¥å…¥
python tests/test_context_tool.py
```

### æµ‹è¯•å†…å®¹

æµ‹è¯•æ–‡ä»¶ä¼šéªŒè¯ï¼š
1. âœ… LLMå®¢æˆ·ç«¯åˆ›å»º
2. âœ… APIè°ƒç”¨æˆåŠŸ
3. âœ… JSONå“åº”è§£æ
4. âœ… ç»“æœæ ¼å¼æ­£ç¡®
5. âœ… å¤šä¸ªæµ‹è¯•ç”¨ä¾‹

### é¢„æœŸè¾“å‡º

```
============================================================
æµ‹è¯•è¯­å¢ƒåˆ†æå·¥å…· (context_tool.py) - ä½¿ç”¨LLM API
============================================================

[1] å‡å€Ÿæ¡ˆä¾‹ï¼šå´‡å€Ÿä¸ºç»ˆ
    åŸå¥: å´‡æœå…¶é›¨
    è¢«é‡Šå­—: å´‡ (æœ¬ä¹‰: é«˜ï¼›é«˜å¤§)
    é‡Šå­—: çµ‚ (æœ¬ä¹‰: ç»ˆç»“ã€æ•´ä¸ª)
    æœŸæœ›ç»“è®º: æ”¯æŒå‡å€Ÿ
    å®é™…ç»“è®º: æ”¯æŒå‡å€Ÿ
    Aæœ¬ä¹‰é€šé¡º: False
    Bæœ¬ä¹‰é€šé¡º: True
    âœ“ ç»“è®ºåŒ¹é…æœŸæœ›
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. APIè°ƒç”¨å¤±è´¥å¤„ç†

å¦‚æœLLM APIè°ƒç”¨å¤±è´¥ï¼Œå·¥å…·ä¼šè‡ªåŠ¨å›é€€åˆ°Mockæ¨¡å¼ï¼š

```python
# å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä¼šçœ‹åˆ°è­¦å‘Š
âš ï¸  LLMè°ƒç”¨å¤±è´¥: ...ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ
```

### 2. æ— ä¸Šä¸‹æ–‡çš„æƒ…å†µ

å¦‚æœæ²¡æœ‰æä¾›ä¸Šä¸‹æ–‡ï¼Œå·¥å…·æ— æ³•è¿›è¡Œè¯­å¢ƒåˆ†æï¼š

```python
result = tool.analyze(
    original_sentence="",  # ç©ºå­—ç¬¦ä¸²
    char_a="å´‡",
    char_b="çµ‚",
    meaning_a="é«˜ï¼›é«˜å¤§",
    meaning_b="ç»ˆç»“ã€æ•´ä¸ª"
)
# ç»“è®ºä¼šæ˜¯"ä¸ç¡®å®š"
```

### 3. æˆæœ¬è€ƒè™‘

æ¯æ¬¡è°ƒç”¨éƒ½ä¼šæ¶ˆè€—APIé¢åº¦ï¼Œå»ºè®®ï¼š
- æ‰¹é‡å¤„ç†æ—¶å¤ç”¨å·¥å…·å®ä¾‹
- æµ‹è¯•æ—¶å¯ä»¥ä½¿ç”¨Mockæ¨¡å¼ï¼ˆä¸ä¼ llm_clientï¼‰

### 4. å“åº”æ—¶é—´

LLM APIè°ƒç”¨éœ€è¦1-3ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚

---

## ğŸ”— ä¸å…¶ä»–å·¥å…·é…åˆä½¿ç”¨

### å®Œæ•´äº”æ­¥åˆ†ææµç¨‹

```python
from openai import OpenAI
from src.tools import (
    query_word_meaning,      # ç¬¬ä¸€æ­¥ï¼šè¯­ä¹‰æŸ¥è¯¢
    query_phonology,         # ç¬¬äºŒæ­¥ï¼šéŸ³éŸµåˆ†æ
    search_textual_evidence, # ç¬¬ä¸‰æ­¥ï¼šæ–‡çŒ®æ£€ç´¢
    identify_pattern,        # ç¬¬å››æ­¥ï¼šè®­å¼è¯†åˆ«
    analyze_context          # ç¬¬äº”æ­¥ï¼šè¯­å¢ƒåˆ†æ
)

# åˆ›å»ºLLMå®¢æˆ·ç«¯
llm_client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
llm_client._model = "qwen3-coder-480b"

# åˆ†æè®­è¯‚å¥ï¼š"å´‡ï¼Œçµ‚ä¹Ÿ"ï¼Œä¸Šä¸‹æ–‡ï¼š"å´‡æœå…¶é›¨"
xungu_sentence = "å´‡ï¼Œçµ‚ä¹Ÿ"
context = "å´‡æœå…¶é›¨"
char_a = "å´‡"
char_b = "çµ‚"

# ç¬¬ä¸€æ­¥ï¼šè¯­ä¹‰åˆ†æ
meaning_a = query_word_meaning(char_a)
meaning_b = query_word_meaning(char_b)

# ç¬¬äºŒæ­¥ï¼šéŸ³éŸµåˆ†æ
phonology = query_phonology(char_a, char_b)

# ç¬¬ä¸‰æ­¥ï¼šæ–‡çŒ®æ£€ç´¢
evidence = search_textual_evidence(char_a, char_b, context)

# ç¬¬å››æ­¥ï¼šè®­å¼è¯†åˆ«
pattern = identify_pattern(xungu_sentence)

# ç¬¬äº”æ­¥ï¼šè¯­å¢ƒåˆ†æï¼ˆä½¿ç”¨LLMï¼‰
context_result = analyze_context(
    original_sentence=context,
    char_a=char_a,
    char_b=char_b,
    meaning_a=meaning_a["æœ¬ä¹‰"],
    meaning_b=meaning_b["æœ¬ä¹‰"],
    llm_client=llm_client
)

# ç»¼åˆåˆ¤æ–­
print("=" * 60)
print("äº”æ­¥åˆ†æç»“æœ")
print("=" * 60)
print(f"è¯­ä¹‰: {meaning_a['æœ¬ä¹‰']} vs {meaning_b['æœ¬ä¹‰']}")
print(f"éŸ³éŸµ: {phonology['éŸ³è¿‘']}")
print(f"æ–‡çŒ®: {evidence['æœ‰ä½è¯']}")
print(f"è®­å¼: {pattern['æš—ç¤ºç±»å‹']}")
print(f"è¯­å¢ƒ: {context_result['ç»“è®º']}")
```

---

## ğŸ“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•çŸ¥é“æ˜¯å¦ä½¿ç”¨äº†LLMï¼Ÿ

**A**: æ£€æŸ¥è¿”å›ç»“æœçš„è¯¦ç»†ç¨‹åº¦ï¼š
- **ä½¿ç”¨LLM**ï¼š`reasoning`å­—æ®µä¼šæœ‰è¯¦ç»†çš„åˆ†æè¯´æ˜
- **ä½¿ç”¨Mock**ï¼š`reasoning`å­—æ®µæ˜¯é¢„è®¾çš„ç®€çŸ­è¯´æ˜

### Q2: APIè°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: å·¥å…·ä¼šè‡ªåŠ¨å›é€€åˆ°Mockæ¨¡å¼ï¼Œä¸ä¼šæŠ¥é”™ã€‚æ£€æŸ¥ï¼š
1. API keyæ˜¯å¦æ­£ç¡®
2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
3. APIæœåŠ¡æ˜¯å¦å¯ç”¨

### Q3: å¦‚ä½•å‡å°‘APIè°ƒç”¨æ¬¡æ•°ï¼Ÿ

**A**: 
1. æ‰¹é‡å¤„ç†æ—¶å¤ç”¨å·¥å…·å®ä¾‹
2. æµ‹è¯•æ—¶ä½¿ç”¨Mockæ¨¡å¼ï¼ˆä¸ä¼ llm_clientï¼‰
3. ç¼“å­˜å·²åˆ†æçš„ç»“æœ

### Q4: å¯ä»¥è‡ªå®šä¹‰æ¨¡å‹å—ï¼Ÿ

**A**: å¯ä»¥ï¼Œåˆ›å»ºå®¢æˆ·ç«¯æ—¶æŒ‡å®šï¼š

```python
client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
client._model = "your-model-name"  # è‡ªå®šä¹‰æ¨¡å‹
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **å·¥å…·APIæ–‡æ¡£**: `docs/TOOLS_API_C.md`
- **å¿«é€Ÿå‚è€ƒ**: `docs/TOOLS_QUICK_C_REFERENCE.md`
- **æµ‹è¯•æ–‡ä»¶**: `tests/test_context_tool.py`

---

## âœ… æ€»ç»“

**ä½¿ç”¨LLM APIçš„æ­¥éª¤**ï¼š

1. âœ… å®‰è£… `openai` åº“ï¼š`pip install openai`
2. âœ… åˆ›å»ºLLMå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨æ‚¨çš„APIé…ç½®ï¼‰
3. âœ… è°ƒç”¨ `analyze_context()` æˆ– `ContextTool.analyze()`
4. âœ… ä¼ å…¥ `llm_client` å‚æ•°
5. âœ… è·å–åˆ†æç»“æœ

**å…³é”®ç‚¹**ï¼š
- å¿…é¡»ä¼ å…¥ `llm_client` æ‰ä¼šä½¿ç”¨çœŸå®LLM API
- ä¸ä¼  `llm_client` ä¼šä½¿ç”¨Mockæ•°æ®
- APIè°ƒç”¨å¤±è´¥ä¼šè‡ªåŠ¨å›é€€åˆ°Mockæ¨¡å¼

---

*æœ€åæ›´æ–°ï¼š2026-01-17*

## ğŸ§ª æµ‹è¯•éªŒè¯

è¿è¡Œæµ‹è¯•æ–‡ä»¶éªŒè¯LLM APIæ¥å…¥ï¼š

```bash
python tests/test_context_tool.py
```

æµ‹è¯•ä¼šï¼š
1. åˆ›å»ºLLMå®¢æˆ·ç«¯
2. è°ƒç”¨çœŸå®çš„LLM API
3. è§£æè¿”å›çš„JSONå“åº”
4. éªŒè¯åˆ†æç»“æœ

## âš™ï¸ é…ç½®è¯´æ˜

### APIé…ç½®ä½ç½®

ä»£ç ä¸­å·²ç¡¬ç¼–ç æ‚¨çš„APIé…ç½®ï¼ˆç¬¬62-64è¡Œï¼‰ï¼š

```python
api_key = settings.openai_api_key or "sk-0d73949767524be2989b35415d2ccbe0"
base_url = settings.openai_base_url or "https://api.tokenpony.cn/v1"
model = settings.llm_model or "qwen3-coder-480b"
```

### ç¯å¢ƒå˜é‡é…ç½®ï¼ˆå¯é€‰ï¼‰

ä¹Ÿå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼š

```bash
export OPENAI_API_KEY="sk-0d73949767524be2989b35415d2ccbe0"
export OPENAI_BASE_URL="https://api.tokenpony.cn/v1"
export LLM_MODEL="qwen3-coder-480b"
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåŸºæœ¬ä½¿ç”¨

```python
from openai import OpenAI
from src.tools.context_tool import ContextTool

# åˆ›å»ºå®¢æˆ·ç«¯
client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
client._model = "qwen3-coder-480b"

# åˆ›å»ºå·¥å…·
tool = ContextTool(llm_client=client)

# åˆ†æ
result = tool.analyze(
    original_sentence="å´‡æœå…¶é›¨",
    char_a="å´‡",
    char_b="çµ‚",
    meaning_a="é«˜ï¼›é«˜å¤§",
    meaning_b="ç»ˆç»“ã€æ•´ä¸ª"
)

print(f"ç»“è®º: {result.conclusion}")
print(f"ç†ç”±: {result.reasoning}")
```

### ç¤ºä¾‹2ï¼šåœ¨Agentä¸­ä½¿ç”¨

```python
from openai import OpenAI
from src.agent.xungu_agent import XunguAgent

# åˆ›å»ºLLMå®¢æˆ·ç«¯
llm_client = OpenAI(
    base_url="https://api.tokenpony.cn/v1",
    api_key="sk-0d73949767524be2989b35415d2ccbe0"
)
llm_client._model = "qwen3-coder-480b"

# åˆ›å»ºAgentï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨LLMè¿›è¡Œè¯­å¢ƒåˆ†æï¼‰
agent = XunguAgent(llm_client=llm_client)

# åˆ†æè®­è¯‚å¥
result = agent.analyze("å´‡ï¼Œçµ‚ä¹Ÿ", context="å´‡æœå…¶é›¨")
```

## âœ… æ¥å…¥çŠ¶æ€æ€»ç»“

| åŠŸèƒ½ | çŠ¶æ€ | è¯´æ˜ |
|------|:----:|------|
| LLM APIè°ƒç”¨ | âœ… å·²å®ç° | `_analyze_with_llm()` æ–¹æ³• |
| å“åº”è§£æ | âœ… å·²å®ç° | `_parse_response()` æ–¹æ³• |
| é”™è¯¯å¤„ç† | âœ… å·²å®ç° | å¤±è´¥æ—¶å›é€€åˆ°mock |
| è‡ªåŠ¨åˆå§‹åŒ– | âœ… å·²å®ç° | `auto_init=True` å‚æ•° |
| APIé…ç½® | âœ… å·²é…ç½® | ç¡¬ç¼–ç äº†æ‚¨çš„API keyå’Œbase_url |
| æµ‹è¯•æ–‡ä»¶ | âœ… å·²åˆ›å»º | `tests/test_context_tool.py` |

## ğŸ¯ å…³é”®ä»£ç ä½ç½®

- **LLMè°ƒç”¨**ï¼šç¬¬124-129è¡Œ
- **å“åº”è§£æ**ï¼šç¬¬142-200è¡Œ
- **å®¢æˆ·ç«¯åˆ›å»º**ï¼šç¬¬53-75è¡Œ
- **æç¤ºè¯æ„å»º**ï¼šç¬¬202-233è¡Œ

---

*æœ€åæ›´æ–°ï¼š2026-01-17*
