# Agentæ¨¡å—ä½¿ç”¨è¯´æ˜

> åŸºäºLangChainæ¡†æ¶çš„è®­è¯‚åˆ†ç±»Agentå®ç°
> 
> è´Ÿè´£äººï¼šæˆå‘˜B

---

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [å®‰è£…ä¸é…ç½®](#å®‰è£…ä¸é…ç½®)
- [æ ¸å¿ƒç±»ä¸æ¥å£](#æ ¸å¿ƒç±»ä¸æ¥å£)
- [äº”æ­¥æ¨ç†æµç¨‹](#äº”æ­¥æ¨ç†æµç¨‹)
- [å·¥å…·ç³»ç»Ÿ](#å·¥å…·ç³»ç»Ÿ)
- [é«˜çº§ç”¨æ³•](#é«˜çº§ç”¨æ³•)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## æ¦‚è¿°

**XunguAgent** æ˜¯åŸºäºLangChain 1.0+æ¡†æ¶å®ç°çš„è®­è¯‚åˆ†ç±»ç³»ç»Ÿæ ¸å¿ƒã€‚å®ƒä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŒ‰ç…§äº”æ­¥æ¨ç†æµç¨‹è‡ªåŠ¨åˆ†æè®­è¯‚å¥ï¼Œåˆ¤æ–­å…¶å±äº"å‡å€Ÿè¯´æ˜"è¿˜æ˜¯"è¯­ä¹‰è§£é‡Š"ã€‚

### ä¸»è¦ç‰¹æ€§

- âœ… **å®Œæ•´çš„äº”æ­¥æ¨ç†** - è¯­ä¹‰â†’éŸ³éŸµâ†’æ–‡çŒ®â†’è®­å¼â†’è¯­å¢ƒ
- âœ… **æ¨¡å—åŒ–å·¥å…·ç³»ç»Ÿ** - 6ä¸ªç‹¬ç«‹çš„å·¥å…·å‡½æ•°ï¼Œå¯çµæ´»ç»„åˆ
- âœ… **åŒLLMæ”¯æŒ** - OpenAI GPT-4 å’Œ Anthropic Claude
- âœ… **è‡ªé€‚åº”æ‰§è¡Œ** - è‡ªåŠ¨è¿­ä»£è°ƒç”¨å·¥å…·ï¼Œæ™ºèƒ½å†³ç­–
- âœ… **è¯¦ç»†æ¨ç†é“¾** - å®Œæ•´ä¿ç•™æ¯ä¸€æ­¥çš„åˆ†æè¿‡ç¨‹
- âœ… **é”™è¯¯å®¹é”™** - è‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œç»§ç»­æ¨ç†

### ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è¾“å…¥ï¼šè®­è¯‚å¥ + ä¸Šä¸‹æ–‡   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    XunguAgent æ ¸å¿ƒ      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ æç¤ºè¯æ„å»º            â”‚
â”‚ â€¢ å·¥å…·ç»‘å®š              â”‚
â”‚ â€¢ æ¨ç†æ‰§è¡Œ              â”‚
â”‚ â€¢ ç»“æœè§£æ              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      SimpleAgentExecutor æ‰§è¡Œå™¨     â”‚
â”‚  ï¼ˆæ›¿ä»£å·²åºŸå¼ƒçš„LangChain Executorï¼‰ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚
    â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM    â”‚    â”‚ Tool å·¥å…·é›†  â”‚
â”‚ (GPT-4/ â”‚    â”‚  (6ä¸ªå·¥å…·)   â”‚
â”‚ Claude) â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â””â”€â†’ è¿­ä»£è°ƒç”¨å·¥å…· â†’â”
                      â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AnalysisResult  â”‚
â”‚  (å®Œæ•´åˆ†æç»“æœ)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å¿«é€Ÿå¼€å§‹

### æœ€ç®€å•çš„ç”¨æ³•

```python
from src.agent import analyze

# ä¸€è¡Œä»£ç åˆ†æè®­è¯‚å¥
result = analyze("å´‡ï¼Œç»ˆä¹Ÿ", context="å´‡æœå…¶é›¨")
print(result["classification"])  # "å‡å€Ÿè¯´æ˜"
print(result["confidence"])      # 0.85
```

### å®Œæ•´çš„ç”¨æ³•

```python
from src.agent import XunguAgent

# åˆ›å»ºAgentå®ä¾‹
agent = XunguAgent(
    llm_provider="openai",      # æˆ– "anthropic"
    verbose=True,               # è¾“å‡ºè¯¦ç»†æ—¥å¿—
    max_iterations=15,          # æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°
    max_execution_time=60       # æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
)

# åˆ†æè®­è¯‚å¥
result = agent.analyze(
    xungu_sentence="å´‡ï¼Œç»ˆä¹Ÿ",
    context="å´‡æœå…¶é›¨",         # å¯é€‰
    source="ã€Šæ¯›ä¼ ã€‹"           # å¯é€‰
)

# æŸ¥çœ‹åˆ†ç±»ç»“æœ
print(f"åˆ†ç±»: {result.classification}")      # "å‡å€Ÿè¯´æ˜" æˆ– "è¯­ä¹‰è§£é‡Š"
print(f"ç½®ä¿¡åº¦: {result.confidence:.0%}")    # 0-100%
print(f"æœ€ç»ˆåˆ¤æ–­: {result.final_reasoning}")

# æŸ¥çœ‹äº”æ­¥æ¨ç†è¿‡ç¨‹
print(f"\nç¬¬ä¸€æ­¥-è¯­ä¹‰æŸ¥è¯¢:\n{result.step1_semantic}")
print(f"\nç¬¬äºŒæ­¥-éŸ³éŸµæŸ¥è¯¢:\n{result.step2_phonetic}")
print(f"\nç¬¬ä¸‰æ­¥-æ–‡çŒ®æ£€ç´¢:\n{result.step3_textual}")
print(f"\nç¬¬å››æ­¥-è®­å¼è¯†åˆ«:\n{result.step4_pattern}")
print(f"\nç¬¬äº”æ­¥-è¯­å¢ƒåˆ†æ:\n{result.step5_context}")

# å¯¼å‡ºä¸ºJSON
json_output = result.to_json()
print(json_output)
```

---

## å®‰è£…ä¸é…ç½®

### ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- LangChain 1.0+
- LLM API Keyï¼ˆOpenAI æˆ– Anthropicï¼‰

### å®‰è£…ä¾èµ–

```bash
# ä»requirements.txtå®‰è£…
pip install -r requirements.txt

# æˆ–æ‰‹åŠ¨å®‰è£…å…³é”®ä¾èµ–
pip install langchain langchain-openai langchain-anthropic
```

### ç¯å¢ƒé…ç½®

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# å¿…é€‰ï¼šLLM API Key äºŒé€‰ä¸€

# OpenAI
OPENAI_API_KEY=sk-your-api-key-here
LLM_MODEL=gpt-4-turbo

# æˆ– Anthropic
ANTHROPIC_API_KEY=sk-ant-your-api-key-here

# å¯é€‰ï¼šå…¶ä»–é…ç½®
OPENAI_BASE_URL=https://api.openai.com/v1  # è‡ªå®šä¹‰APIç«¯ç‚¹
LLM_PROVIDER=openai                         # é»˜è®¤LLMæä¾›å•†
```

### éªŒè¯å®‰è£…

```python
# æµ‹è¯•LLMè¿æ¥
from src.agent.llm_client import get_llm

llm = get_llm()
print("âœ… LLMè¿æ¥æˆåŠŸ")

# æµ‹è¯•å·¥å…·ç³»ç»Ÿ
from src.agent.tool_wrappers import get_all_tools

tools = get_all_tools()
print(f"âœ… å·¥å…·ç³»ç»Ÿå°±ç»ªï¼Œå…±{len(tools)}ä¸ªå·¥å…·")

# æµ‹è¯•Agent
from src.agent import XunguAgent

agent = XunguAgent(verbose=False)
result = agent.analyze("æ­£ï¼Œè¯»ä¸ºå¾")
print(f"âœ… Agentå¯ç”¨ï¼Œåˆ†ç±»ç»“æœ: {result.classification}")
```

---

## æ ¸å¿ƒç±»ä¸æ¥å£

### AnalysisResultï¼ˆåˆ†æç»“æœç±»ï¼‰

ä»£è¡¨Agentçš„å®Œæ•´åˆ†æè¾“å‡ºã€‚

**å…³é”®å­—æ®µ**:

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `classification` | str | åˆ†ç±»ç»“æœï¼š"å‡å€Ÿè¯´æ˜" æˆ– "è¯­ä¹‰è§£é‡Š" |
| `confidence` | float | ç½®ä¿¡åº¦ (0.0-1.0) |
| `step1_semantic` | Dict | ç¬¬ä¸€æ­¥ï¼šè¯­ä¹‰æŸ¥è¯¢ç»“æœ |
| `step2_phonetic` | Dict | ç¬¬äºŒæ­¥ï¼šéŸ³éŸµæŸ¥è¯¢ç»“æœ |
| `step3_textual` | Dict | ç¬¬ä¸‰æ­¥ï¼šæ–‡çŒ®æ£€ç´¢ç»“æœ |
| `step4_pattern` | Dict | ç¬¬å››æ­¥ï¼šè®­å¼è¯†åˆ«ç»“æœ |
| `step5_context` | Dict | ç¬¬äº”æ­¥ï¼šè¯­å¢ƒåˆ†æç»“æœ |
| `final_reasoning` | str | æœ€ç»ˆæ¨ç†è¯´æ˜ |

**å¸¸ç”¨æ–¹æ³•**:

```python
# è½¬æ¢ä¸ºå­—å…¸
result_dict = result.to_dict()

# è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
json_str = result.to_json(indent=2)

# è®¿é—®å­—æ®µ
print(result.classification)
print(result.step1_semantic)
```

### XunguAgentï¼ˆAgentç±»ï¼‰

ç³»ç»Ÿçš„æ ¸å¿ƒæ¨ç†å¼•æ“ã€‚

**åˆå§‹åŒ–å‚æ•°**:

```python
agent = XunguAgent(
    llm_provider="openai",          # LLMæä¾›å•†ï¼šopenai æˆ– anthropic
    verbose=True,                   # æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
    max_iterations=15,              # æœ€å¤§è¿­ä»£æ¬¡æ•°
    max_execution_time=60           # æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
)
```

**æ ¸å¿ƒæ–¹æ³•**:

```python
# åˆ†æè®­è¯‚å¥
result = agent.analyze(
    xungu_sentence="å´‡ï¼Œç»ˆä¹Ÿ",      # å¿…éœ€ï¼šè®­è¯‚å¥
    context="å´‡æœå…¶é›¨",             # å¯é€‰ï¼šä¸Šä¸‹æ–‡
    source="ã€Šæ¯›ä¼ ã€‹"               # å¯é€‰ï¼šå‡ºå¤„
)
```

---

## äº”æ­¥æ¨ç†æµç¨‹

AgentæŒ‰ç…§ä»¥ä¸‹äº”æ­¥è‡ªåŠ¨åˆ†æè®­è¯‚å¥ï¼š

### ç¬¬ä¸€æ­¥ï¼šè¯­ä¹‰æŸ¥è¯¢

**å·¥å…·**: `query_word_meaning()`

**åŠŸèƒ½**: æŸ¥è¯¢è¢«é‡Šå­—å’Œé‡Šå­—çš„æœ¬ä¹‰ï¼Œåˆ¤æ–­ä¹‰è¿‘/ä¹‰è¿œ

**è¾“å‡ºç¤ºä¾‹**:
```json
{
    "å­—": "å´‡",
    "æœ¬ä¹‰": "é«˜å¤§",
    "ä¹‰é¡¹": ["é«˜å¤§", "å°Šå´‡", "å´‡æ‹œ"],
    "ä¾‹å¥": ["..."]
}
```

**åˆ¤æ–­ä¾æ®**:
- ğŸŸ¢ ä¹‰è¿‘ â†’ æ”¯æŒ"è¯­ä¹‰è§£é‡Š"
- ğŸ”´ ä¹‰è¿œ â†’ æ”¯æŒ"å‡å€Ÿè¯´æ˜"

---

### ç¬¬äºŒæ­¥ï¼šéŸ³éŸµæŸ¥è¯¢

**å·¥å…·**: `query_phonology()` + `check_phonetic_relation()`

**åŠŸèƒ½**: æŸ¥è¯¢ä¸Šå¤éŸ³ï¼Œåˆ¤æ–­ä¸¤å­—æ˜¯å¦éŸ³è¿‘

**è¾“å‡ºç¤ºä¾‹**:
```json
{
    "is_close": true,
    "same_yunbu": true,        # åŒéŸµéƒ¨
    "same_shengmu": false,     # ä¸åŒå£°æ¯
    "char1_info": {...},
    "char2_info": {...}
}
```

**åˆ¤æ–­ä¾æ®**:
- ğŸŸ¢ éŸ³è¿‘ + ä¹‰è¿œ â†’ æ”¯æŒ"å‡å€Ÿè¯´æ˜"
- ğŸ”´ éŸ³è¿‘ + ä¹‰è¿‘ â†’ å¯èƒ½"ä»¥å£°é€šä¹‰"ï¼ˆç‰¹æ®Šçš„è¯­ä¹‰è§£é‡Šï¼‰

---

### ç¬¬ä¸‰æ­¥ï¼šæ–‡çŒ®æ£€ç´¢

**å·¥å…·**: `search_textual_evidence()`

**åŠŸèƒ½**: æ£€ç´¢è¯å…¸ä¸­çš„å¼‚æ–‡ã€å‡å€Ÿæ ‡æ³¨ç­‰ä½è¯

**è¾“å‡ºç¤ºä¾‹**:
```json
{
    "æœ‰ä½è¯": true,
    "å¼‚æ–‡": [...],
    "å‡å€Ÿè®°å½•": [
        {
            "source": "ã€Šæ¯›ä¼ ã€‹",
            "text": "è¯»ä¸ºç»ˆ"
        }
    ]
}
```

**åˆ¤æ–­ä¾æ®**:
- ğŸŸ¢ æœ‰å‡å€Ÿè®°å½• â†’ å¼ºçƒˆæ”¯æŒ"å‡å€Ÿè¯´æ˜"
- ğŸŸ¡ æœ‰å¼‚æ–‡ä½†æ— å‡å€Ÿè®°å½• â†’ ä¸­ç­‰æ”¯æŒ

---

### ç¬¬å››æ­¥ï¼šè®­å¼è¯†åˆ«

**å·¥å…·**: `identify_pattern()`

**åŠŸèƒ½**: è¯†åˆ«è®­è¯‚å¥çš„æ ¼å¼ï¼ˆå¦‚"è¯»ä¸º"ã€"çŠ¹ä¹Ÿ"ç­‰ï¼‰ï¼Œåˆ¤æ–­æ˜¯å¦ç›´æ¥æš—ç¤ºå‡å€Ÿ

**æ”¯æŒçš„æ ¼å¼**:
- `è¯»ä¸º` â†’ æå¼ºæš—ç¤º"å‡å€Ÿ"
- `è°“ä¹‹` / `ä¹‹è°“` â†’ å¯èƒ½"å‡å€Ÿ"æˆ–"è¯­ä¹‰"
- `çŠ¹` / `çŠ¹ä¹Ÿ` â†’ ä¸­ç­‰æš—ç¤º"è¯­ä¹‰è§£é‡Š"
- `æ­£` / `ä¸º` â†’ å¼±æš—ç¤º"è¯­ä¹‰è§£é‡Š"
- å…¶ä»–æ ¼å¼ â†’ å¼±æš—ç¤º

**è¾“å‡ºç¤ºä¾‹**:
```json
{
    "æ ¼å¼": "è¯»ä¸º",
    "æš—ç¤ºç±»å‹": "å‡å€Ÿ",
    "ç½®ä¿¡åº¦": "æé«˜",
    "å¯ç›´æ¥åˆ¤å®š": true
}
```

**åˆ¤æ–­ä¾æ®**:
- ğŸŸ¢ æ ¼å¼ç›´æ¥æš—ç¤º â†’ å¯ç›´æ¥åˆ¤å®š
- ğŸŸ¡ æ ¼å¼å¼±æš—ç¤º â†’ éœ€è¦ç»“åˆå…¶ä»–æ­¥éª¤

---

### ç¬¬äº”æ­¥ï¼šè¯­å¢ƒåˆ†æ

**å·¥å…·**: `analyze_context()`

**åŠŸèƒ½**: åˆ†æè¯­å¢ƒï¼Œåˆ¤æ–­è¢«é‡Šå­—/é‡Šå­—çš„æœ¬ä¹‰ä»£å…¥åæ˜¯å¦é€šé¡º

**è¾“å‡ºç¤ºä¾‹**:
```json
{
    "Aæœ¬ä¹‰é€šé¡º": false,
    "Bæœ¬ä¹‰é€šé¡º": true,
    "ç»“è®º": "æ”¯æŒå‡å€Ÿ",
    "ç†ç”±": "Açš„æœ¬ä¹‰ä»£å…¥ä¸é€šï¼ŒBçš„æœ¬ä¹‰ä»£å…¥é€šé¡º"
}
```

**åˆ¤æ–­ä¾æ®**:
- ğŸŸ¢ Aä¹‰ä»£å…¥ä¸é€šï¼ŒBä¹‰ä»£å…¥é€šé¡º â†’ æ”¯æŒ"å‡å€Ÿè¯´æ˜"
- ğŸŸ¡ Aä¹‰ä»£å…¥é€šé¡ºï¼ŒBä¹‰ä»£å…¥ä¹Ÿé€šé¡º â†’ æ”¯æŒ"è¯­ä¹‰è§£é‡Š"

---

## å·¥å…·ç³»ç»Ÿ

### 6ä¸ªå†…ç½®å·¥å…·

| å·¥å…· | åŠŸèƒ½ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| `query_word_meaning` | æŸ¥è¯¢å­—ä¹‰ | å•ä¸ªæ±‰å­— | æœ¬ä¹‰ã€ä¹‰é¡¹ã€ä¾‹å¥ |
| `query_phonology` | æŸ¥è¯¢éŸ³éŸµ | å•ä¸ªæ±‰å­— | å£°æ¯ã€éŸµéƒ¨ã€æ‹ŸéŸ³ |
| `check_phonetic_relation` | æ¯”è¾ƒéŸ³éŸµ | ä¸¤ä¸ªæ±‰å­— | éŸ³è¿‘ã€éŸµéƒ¨ã€å£°æ¯ |
| `search_textual_evidence` | æ£€ç´¢æ–‡çŒ® | ä¸¤ä¸ªæ±‰å­—+ä¸Šä¸‹æ–‡ | å¼‚æ–‡ã€å‡å€Ÿè®°å½• |
| `identify_pattern` | è¯†åˆ«è®­å¼ | è®­è¯‚å¥å­—ç¬¦ä¸² | æ ¼å¼ã€æš—ç¤ºç±»å‹ |
| `analyze_context` | åˆ†æè¯­å¢ƒ | å¥å­ã€ä¸¤ä¸ªå­—ã€ä¸¤ä¸ªä¹‰é¡¹ | é€šé¡ºæ€§ã€ç»“è®º |

### å·¥å…·è°ƒç”¨æ–¹å¼

```python
# ç›´æ¥è°ƒç”¨å·¥å…·å‡½æ•°
from src.tools import query_word_meaning, check_phonetic_relation

meaning = query_word_meaning("å´‡")
phonetic = check_phonetic_relation("å´‡", "ç»ˆ")

# æˆ–åœ¨Agentä¸­è‡ªåŠ¨è°ƒç”¨
agent = XunguAgent(verbose=True)  # verbose=Trueæ—¶å¯çœ‹åˆ°å·¥å…·è°ƒç”¨è¿‡ç¨‹
result = agent.analyze("å´‡ï¼Œç»ˆä¹Ÿ")  # Agentä¼šè‡ªåŠ¨å†³å®šè°ƒç”¨å“ªäº›å·¥å…·
```

---

## é«˜çº§ç”¨æ³•

### æ‰¹é‡åˆ†æ

```python
from src.agent import XunguAgent
import json

agent = XunguAgent(verbose=False)

# æ‰¹é‡åˆ†æ
sentences = [
    {"text": "å´‡ï¼Œç»ˆä¹Ÿ", "context": "å´‡æœå…¶é›¨"},
    {"text": "æ­£ï¼Œè¯»ä¸ºå¾", "context": None},
    {"text": "é¬¼ï¼Œéšä¹Ÿ", "context": "é¬¼åœ¨æš—å¤„"},
]

results = []
for item in sentences:
    result = agent.analyze(
        xungu_sentence=item["text"],
        context=item.get("context")
    )
    results.append(result.to_dict())

# ä¿å­˜ç»“æœ
with open("results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)
```

### è‡ªå®šä¹‰LLMæ¨¡å‹

```python
from src.agent import XunguAgent
from src.agent.llm_client import get_llm

# ä½¿ç”¨Anthropic Claude
agent = XunguAgent(llm_provider="anthropic", verbose=True)
result = agent.analyze("å´‡ï¼Œç»ˆä¹Ÿ")

# æˆ–æ‰‹åŠ¨åˆ›å»ºLLMå¹¶ä¼ å…¥
from src.config import get_settings
settings = get_settings()
# ... è‡ªå®šä¹‰LLMé…ç½®
```

### è°ƒæ•´æ¨ç†å‚æ•°

```python
# è°ƒæ•´è¿­ä»£æ¬¡æ•°å’Œè¶…æ—¶æ—¶é—´
agent = XunguAgent(
    max_iterations=20,          # å¢åŠ å·¥å…·è°ƒç”¨æ¬¡æ•°
    max_execution_time=120      # å¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
)

# å¿«é€Ÿæ¨¡å¼
fast_agent = XunguAgent(
    max_iterations=5,           # å¿«é€Ÿæ¨¡å¼ï¼šå°‘æ¬¡è¿­ä»£
    max_execution_time=30       # å¿«é€Ÿæ¨¡å¼ï¼š30ç§’è¶…æ—¶
)
```

### é›†æˆåˆ°å…¶ä»–ç³»ç»Ÿ

```python
# Flask Webåº”ç”¨
from flask import Flask, request, jsonify
from src.agent import XunguAgent

app = Flask(__name__)
agent = XunguAgent(verbose=False)

@app.route("/analyze", methods=["POST"])
def analyze():
    data = request.json
    result = agent.analyze(
        xungu_sentence=data.get("sentence"),
        context=data.get("context")
    )
    return jsonify(result.to_dict())

# FastAPIåº”ç”¨
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()
agent = XunguAgent(verbose=False)

class XunguRequest(BaseModel):
    sentence: str
    context: str = None

@app.post("/analyze")
async def analyze(req: XunguRequest):
    result = agent.analyze(req.sentence, context=req.context)
    return result.to_dict()
```

---

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•è®¾ç½®API Keyï¼Ÿ

**A**: åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
OPENAI_API_KEY=sk-xxx
# æˆ–
ANTHROPIC_API_KEY=sk-ant-xxx
```

### Q: Agentåˆ†æå¾ˆæ…¢ï¼Œå¦‚ä½•åŠ å¿«ï¼Ÿ

**A**: 

1. å‡å°‘ `max_iterations`ï¼š
```python
agent = XunguAgent(max_iterations=10)  # é»˜è®¤15
```

2. å‡å°‘ `max_execution_time`ï¼š
```python
agent = XunguAgent(max_execution_time=30)  # é»˜è®¤æ— é™åˆ¶
```

3. ä½¿ç”¨ `verbose=False` å…³é—­æ—¥å¿—è¾“å‡º

### Q: å¦‚ä½•åªä½¿ç”¨æŸäº›å·¥å…·ï¼Ÿ

**A**: ç›®å‰Agentè‡ªåŠ¨é€‰æ‹©å·¥å…·ã€‚å¦‚éœ€æ‰‹åŠ¨æ§åˆ¶ï¼Œå¯ç›´æ¥è°ƒç”¨å·¥å…·å‡½æ•°ï¼š

```python
from src.tools import identify_pattern, check_phonetic_relation

# åªè¯†åˆ«è®­å¼å’ŒéŸ³éŸµ
pattern = identify_pattern("å´‡ï¼Œç»ˆä¹Ÿ")
phonetic = check_phonetic_relation("å´‡", "ç»ˆ")
```

### Q: Agentè¿”å›ç»“æœé”™è¯¯ï¼Œæ€ä¹ˆåŠï¼Ÿ

**A**:

1. æ£€æŸ¥API Keyæ˜¯å¦æ­£ç¡®è®¾ç½®
2. å¯ç”¨ `verbose=True` æŸ¥çœ‹æ¨ç†è¿‡ç¨‹
3. æ£€æŸ¥è¢«åˆ†æçš„è®­è¯‚å¥æ ¼å¼æ˜¯å¦æ­£ç¡®
4. æ£€æŸ¥æ˜¯å¦éœ€è¦æ„å»ºè¯å…¸ç´¢å¼•

### Q: å¦‚ä½•æ‰©å±•AgentåŠŸèƒ½ï¼Ÿ

**A**: åœ¨ `tool_wrappers.py` ä¸­æ·»åŠ æ–°å·¥å…·ï¼š

```python
from langchain_core.tools import StructuredTool

def new_tool() -> StructuredTool:
    return StructuredTool.from_function(
        func=your_function,
        name="tool_name",
        description="Tool description"
    )

# åœ¨ get_all_tools() ä¸­æ·»åŠ 
def get_all_tools():
    return [
        # ... ç°æœ‰å·¥å…·
        new_tool(),  # æ–°å·¥å…·
    ]
```

---

## æ›´å¤šèµ„æº

- **è¯¦ç»†APIæ–‡æ¡£**: è§ [`docs/API.md`](../docs/API.md)
- **å®Œæ•´å®ç°ä»£ç **: è§ [`xungu_agent.py`](xungu_agent.py)
- **é¡¹ç›®å®Œæˆåº¦**: è§ [`docs/COMPLETION.md`](../docs/COMPLETION.md)
- **å¼€å‘æŒ‡å—**: è§ [`AGENT_DEVELOPMENT_GUIDE.md`](AGENT_DEVELOPMENT_GUIDE.md)

---

*æ–‡æ¡£æœ€åæ›´æ–°: 2026å¹´1æœˆ18æ—¥*

